# Readme

## Setting up the environment
Our goal is to run `jaxmarl_testdrive.py`. This is a basic script that you should only be able to run if you have everything installed correctly, which should be the case by the end of this section. I've only tested this out on macOS with an M1 chip.

1. Make a conda environment with `conda create -n siggame python=3.9`
2. Activate the environment with `conda activate siggame`
3. Install jax. If you're on macOS, you can run this if you are using conda:
    ```shell
    conda install -c conda-forge jaxlib=0.4.19
    conda install -c conda-forge jax
    ```
    Or you can run this if you are using mamba (better):
    ```shell
    mamba install jaxlib=0.4.19
    mamba install jax
    ```
    Verify that it is installed correctly by running 
    ```python -c 'import jax; print(jax.numpy.arange(10))'```
    You may get some warnings but you should end up with a list of 0-9.
4. Install JaxMARL. This cannot be done with pip, since we need to run the algorithms (See [JaxMARL installation instructions](https://github.com/FLAIROx/JaxMARL/tree/main?tab=readme-ov-file#installation--) for why).
Clone JaxMARL in a separate directory with:
    ```shell
    git clone https://github.com/FLAIROx/JaxMARL.git && cd JaxMARL
    pip install -e .
    ```
5. If you're on mac, you may still struggle to run `jaxmarl_testdrive.py` because you'll get a MuJoCo error. However, we don't really care about MuJoCo, so you can just comment out the following lines in the JaxMARL package (I hate how dirty this is):
    ```python
    # In /JaxMARL/jaxmarl/environments/__init__.py comment out line 20
    ...
    from .overcooked import Overcooked, overcooked_layouts
    # from .mabrax import Ant, Humanoid, Hopper, Walker2d, HalfCheetah
    from .hanabi import HanabiGame
    ...
    ```
    ```python
    # In /JaxMARL/jaxmarl/registration.py comment out lines 19-23
    ...
    HeuristicEnemySMAX,
    LearnedPolicyEnemySMAX,
    SwitchRiddle,
    # Ant,
    # Humanoid,
    # Hopper,
    # Walker2d,
    # HalfCheetah,
    InTheGrid,
    InTheGrid_2p,
    HanabiGame,
    ...
    ```
    This should work for `JaxMARL v0.0.2`. If you're using a different version, you may need to find the lines yourself.
6. We also need torch and torchvision, which can be installed with mamba:
    ```shell
    mamba install torchvision
    ```
    The conda analog would be something like (untested):
    ```shell
    conda install -c conda-forge torchvision
    ```
7. We also need jax-dataloader, which can be installed with pip:
    ```shell
    pip install jax-dataloader
    ```

## SimplifiedSignificationGame
This environment setup is slightly confusing. Let's take a look at the State class:
```python
class State:
    # Newly generated, to be evaluated next state after speakers generate images
    new_channel_class_assignment: chex.Array  # [num_classes] * num_listeners    # Each index is the class of the image at that index. Location not randomized.
    new_env_images: chex.Array  # [image_size] * num_listeners
    new_listener_image_from_env_or_speaker_mask: chex.Array  # [bool] * num_listeners
    new_listener_channel_assignment: chex.Array  # [max(num_speakers, num_listers)] * num_listeners     # This tells the listener which image to classify, either from the environment (new_env_images[i]) or from the speaker (ON THE NEXT STATE, speaker_images[i])

    # Newly generated as a function of previous state, to be evaluated this state
    speaker_images: chex.Array  # [image_size] * num_speakers       # Each index is the image generated by the speaker at that index (the actual channel). Location not randomized.

    # From previous state, to be evaluated this state
    old_env_images: chex.Array  # [image_size] * num_listeners      # Each index is the image from the environment at that index (the actual channel). Location not randomized.
    old_channel_class_assignment: chex.Array  # [num_classes] * num_listeners
    old_listener_image_from_env_or_speaker_mask: chex.Array  # [bool] * num_listeners
    old_listener_channel_assignment: chex.Array  # [max(num_speakers, num_listers)] * num_listeners     # This tells the listener which image to classify, either from the environment (old_env_images[i]) or from the speaker (speaker_images[i])

    iteration: int
```
At each state, the environment actually has a foot in two rounds of the game. This is because the speaker and listener are asynchronous. In order for the speaker to generate images, it needs to know what classes to generate, which are sampled at the current time step. However, the listener needs to see the images generated in order to classify them, but we must wait a turn for the speakers to generate the images before we can do that. Therefore, at the current time step, the speakers have just generated new images (to be classified by listeners by the next state), and the listeners have just classified the previous images.

To keep track of these two consecutive rounds, all variables prefixed with `new_` are generated at the current time step and intended for the next round, and all variables prefixed with `old_` were generated at the previous time step and are intended for the current round (during the last round, they were generated as `new_` variables and then simply copied over into `old_` variables). Importantly, `speaker_images` corresponds to the `old_` variables! The speakers have just completed the current round, and the speaker images for the `new_` variables haven't been generated yet!

The environment is composed of two sets of fixed communication channels, one channel contains images from the environment (`old_env_images`) and the other contains images from the speakers (`speaker_images`). The true labels for these images are stored in `old_channel_class_assignment`[^1]. The listeners are then tasked with classifying images from the two channels. The `old_listener_image_from_env_or_speaker_mask` is a binary mask that tells the listener whether to classify an image from the environment or from the speaker. Then, `old_listener_channel_assignment` tells the listener which index of the channel (and therefore which image) it should classify. The listener is rewarded for classifying the image correctly; in the case that the listener classified a speaker's image, that speaker is also rewarded (or punished) accordingly.

[^1]: There is always a 1 to 1 mapping from `old_env_images` to `old_channel_class_assignment`, because they were originally sampled from a dataloader:
    ```python
    new_env_images, new_channel_class_assignment = next(iter(self.dataloader))
    ```
    However, there may be a smaller or larger number of speakers than there are channels (as specified by the user with `num_speakers`). In these cases, up to the first `len(old_channel_class_assignment)` speakers are assigned the classes in `old_channel_class_assignment` in order. We haven't worked out the remaining speakers yet, but we'll get to that. For now that means you should ensure that `num_speakers <= num_listeners`.
